{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "1.  Define and build a PyTorch Dataset\n",
    "\"\"\"\n",
    "class CIFAR10(Dataset):\n",
    "    def __init__(self, data_files, transform=None, target_transform=None):\n",
    "        \n",
    "        self.image_data = []\n",
    "        self.image_labels = []\n",
    "        for i in range(len(data_files)):\n",
    "            data_dict = unpickle(data_files[i])\n",
    "            # self.image_data += data_dict[b'data']\n",
    "            if isinstance(self.image_data, list):\n",
    "                self.image_data = data_dict[b'data']\n",
    "            else:\n",
    "                # Stack vertically (for 2D data)\n",
    "                self.image_data = np.vstack((self.image_data, data_dict[b'data']))\n",
    "            \n",
    "            self.image_labels += data_dict[b'labels']\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        # print(type(self.image_data[0]))\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.image_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.image_data[idx]\n",
    "        image = image.reshape(3,32,32)\n",
    "        image = image.transpose(1,2,0)\n",
    "        label = self.image_labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return (image, label)\n",
    "    \n",
    "\n",
    "def get_preprocess_transform(mode):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    return transform\n",
    "\n",
    "\n",
    "def build_dataset(data_files, transform=None):\n",
    "\n",
    "    dataset = CIFAR10(data_files, transform)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "2.  Build a PyTorch DataLoader\n",
    "\"\"\"\n",
    "def build_dataloader(dataset, loader_params):\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=loader_params[\"batch_size\"], shuffle=loader_params[\"shuffle\"])\n",
    "    # dataloader = DataLoader(dataset)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "3. (a) Build a neural network class.\n",
    "\"\"\"\n",
    "class FinetuneNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
    "        \n",
    "        self.hidden1 = torch.nn.Linear(32 * 8 * 8, 250)\n",
    "        self.hidden2 = torch.nn.Linear(250, 10)\n",
    "        self.relu = torch.nn.ReLU() \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.unflatten(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "\n",
    "        x = self.hidden1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.hidden2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "3. (b)  Build a model\n",
    "\"\"\"\n",
    "def build_model(trained=False):\n",
    "\n",
    "    net = FinetuneNet()\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "4.  Build a PyTorch optimizer\n",
    "\"\"\"\n",
    "def build_optimizer(optim_type, model_params, hparams):\n",
    "\n",
    "    if optim_type == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(params=model_params, lr=hparams)\n",
    "    if optim_type == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(params=model_params, lr=hparams)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "5. Training loop for model\n",
    "\"\"\"\n",
    "def train(train_dataloader, model, loss_fn, optimizer):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "\n",
    "    for epoch in range(38):\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # losses.append(loss.detach().numpy())\n",
    "            # losses.append(float(loss))\n",
    "            total_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(pred, 1)\n",
    "            correct_predictions += (predicted_labels == y).sum().item()\n",
    "            total_predictions += y.size(0)\n",
    "\n",
    "        epoch_loss = total_loss / len(train_dataloader)\n",
    "        epoch_accuracy = correct_predictions / total_predictions\n",
    "        loss_history.append(epoch_loss)\n",
    "        accuracy_history.append(epoch_accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Loss: {epoch_loss}, Accuracy: {epoch_accuracy}')\n",
    "\n",
    "    # plt.plot(losses)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(loss_history, label='Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting the accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(accuracy_history, label='Accuracy', color='orange')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "'''Run model'''\n",
    "def run_model():\n",
    "\n",
    "    new_model = build_model()\n",
    "    train_dataset = build_dataset(['cifar-10-batches-py/data_batch_1', \n",
    "                                   'cifar-10-batches-py/data_batch_2', \n",
    "                                   'cifar-10-batches-py/data_batch_3', \n",
    "                                   'cifar-10-batches-py/data_batch_4', \n",
    "                                   'cifar-10-batches-py/data_batch_5'], transform=get_preprocess_transform(train))\n",
    "    \n",
    "    train_params = {\"batch_size\": 64, \"shuffle\": True}\n",
    "    train_dataloader = build_dataloader(train_dataset, train_params)   \n",
    "    # train_dataloader = build_dataloader(train_dataset)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = build_optimizer(\"Adam\", new_model.parameters(), hparams=0.01)\n",
    "    train(train_dataloader, new_model, loss_fn, optimizer)\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# it make take a little while to build the dataset \n",
    "example_dataset = build_dataset([\"cifar-10-batches-py/data_batch_1\"], transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
